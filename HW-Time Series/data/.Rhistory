dist_points[2,1]
dist_points[3,1]
dist_points[1,3]
head(df_index)
# re=order matrix for weight matrix
dist_points = dist_points[df_index[,'large_matrix_index'],df_index[,'large_matrix_index']]
dist_point[1,2]
dist_points[1,2]
dist_points[2,1]
dist_points[10,3]
dist_points[3,10]
dim(dist_points)
# replace distance points in the weight matrix
weight_matrix[indices,indices] = dist_points
smi = smi_list[2]
# get all observaionts from smi
temp_panel = df_panel[df_panel['Scantrack_Market_Identifier_Cd']==smi,]
# get number of observations from smi
N_smi = dim(temp_panel)[1]
# create index for using in the weight matrix
if(is.null(end_index)){
end_index = N_smi
}else{
start_index = end_index + 1
end_index = start_index + N_smi
}
indices = start_index:end_index
indices
# list of zip codes
zip_list = as.vector(temp_panel[,'Panelist_ZipCd'])
# zip to zctas
df_index = data.frame(large_matrix_index=indices,zip=zip_list)
length(indices)
length(zip_list)
# create indices for subjects since we are doing this by smi
start_index = 1
end_index = NULL
# by smi, get all the zips and find the distance between them
smi_list = unique(df_panel[,'Scantrack_Market_Identifier_Cd'])
smi = smi_list[1]
# get all observaionts from smi
temp_panel = df_panel[df_panel['Scantrack_Market_Identifier_Cd']==smi,]
# get number of observations from smi
N_smi = dim(temp_panel)[1]
# create index for using in the weight matrix
if(is.null(end_index)){
end_index = N_smi
}else{
start_index = end_index + 1
end_index = start_index + N_smi
}
smi = smi_list[2]
# get all observaionts from smi
temp_panel = df_panel[df_panel['Scantrack_Market_Identifier_Cd']==smi,]
# get number of observations from smi
N_smi = dim(temp_panel)[1]
N_smi
# create index for using in the weight matrix
if(is.null(end_index)){
end_index = N_smi
}else{
start_index = end_index + 1
end_index = start_index + N_smi
}
start_index
end_index
indices = start_index:end_index
length(indices)
N_smi
start_index = end_index + 1
end_index = start_index + N_smi - 1
# create indices for subjects since we are doing this by smi
start_index = 1
end_index = NULL
# by smi, get all the zips and find the distance between them
smi_list = unique(df_panel[,'Scantrack_Market_Identifier_Cd'])
smi = smi_list[1]
# get all observaionts from smi
temp_panel = df_panel[df_panel['Scantrack_Market_Identifier_Cd']==smi,]
# get number of observations from smi
N_smi = dim(temp_panel)[1]
# create index for using in the weight matrix
if(is.null(end_index)){
end_index = N_smi
}else{
start_index = end_index + 1
end_index = start_index + N_smi - 1
}
smi = smi_list[2]
# get all observaionts from smi
temp_panel = df_panel[df_panel['Scantrack_Market_Identifier_Cd']==smi,]
# get number of observations from smi
N_smi = dim(temp_panel)[1]
# create index for using in the weight matrix
if(is.null(end_index)){
end_index = N_smi
}else{
start_index = end_index + 1
end_index = start_index + N_smi - 1
}
indices = start_index:end_index
length(indices)
# list of zip codes
zip_list = as.vector(temp_panel[,'Panelist_ZipCd'])
# zip to zctas
df_index = data.frame(large_matrix_index=indices,zip=zip_list)
df_index = merge(df_index,
zip_to_zcta,
by.x=c('zip'),
by.y=c('ZIP'))
# pad 0s for zips
padded_zip = c()
for(zip in zip_list){
if(nchar(zip)<5){
padded_zip = c(padded_zip,paste(c(rep("0",5-nchar(zip)),zip),collapse=''))
}else{
padded_zip = c(padded_zip,zip)
}
}
# get polygons for list of zips
df <- zctas(cb = TRUE, starts_with = padded_zip,refresh=TRUE,year=2010)
# create zcta index
zcta_index = 1:dim(df)[1]
df_zcta = data.frame(ZCTA=df@data[,'ZCTA5'],submatrix_index=zcta_index)
df_index = merge(df_index,
df_zcta,
by=c('ZCTA'))
# find center of polygons
polygon_centroids = gCentroid(df,byid=TRUE)
# get distance between points
# distance is in meters
dist_points = pointDistance(coordinates(polygon_centroids),coordinates(polygon_centroids),lonlat=TRUE,allpairs=T)
dist_points = Matrix(as.matrix(dist_points/1000),sparse=TRUE) #meters -> kilometers
# re-order matrix for submatrix
dist_points = dist_points[df_index[,'submatrix_index'],]
dist_points = dist_points[,df_index[,'submatrix_index']]
# re=order matrix for weight matrix
dist_points = dist_points[df_index[,'large_matrix_index'],df_index[,'large_matrix_index']]
# replace distance points in the weight matrix
weight_matrix[indices,indices] = dist_points
df_index[,'large_matrix_index']
# zip to zctas
df_index = data.frame(large_matrix_index=indices,zip=zip_list,sort_index=1:N_smi)
df_index = merge(df_index,
zip_to_zcta,
by.x=c('zip'),
by.y=c('ZIP'))
# pad 0s for zips
padded_zip = c()
for(zip in zip_list){
if(nchar(zip)<5){
padded_zip = c(padded_zip,paste(c(rep("0",5-nchar(zip)),zip),collapse=''))
}else{
padded_zip = c(padded_zip,zip)
}
}
# get polygons for list of zips
df <- zctas(cb = TRUE, starts_with = padded_zip,refresh=TRUE,year=2010)
# re=order matrix for weight matrix
dist_points = dist_points[df_index[,'large_matrix_index']-N_smi,df_index[,'large_matrix_index']-N_smi]
min(df_index[,'large_matrix_index']-N_smi)
# re-order matrix for submatrix
dist_points = dist_points[df_index[,'submatrix_index']-N_smi,]
df_index[,'submatrix_index']
# zip to zctas
df_index = data.frame(large_matrix_index=indices,zip=zip_list,sort_index=1:N_smi)
df_index = merge(df_index,
zip_to_zcta,
by.x=c('zip'),
by.y=c('ZIP'))
# pad 0s for zips
padded_zip = c()
for(zip in zip_list){
if(nchar(zip)<5){
padded_zip = c(padded_zip,paste(c(rep("0",5-nchar(zip)),zip),collapse=''))
}else{
padded_zip = c(padded_zip,zip)
}
}
# get polygons for list of zips
df <- zctas(cb = TRUE, starts_with = padded_zip,refresh=TRUE,year=2010)
# create zcta index
zcta_index = 1:dim(df)[1]
df_zcta = data.frame(ZCTA=df@data[,'ZCTA5'],submatrix_index=zcta_index)
df_index = merge(df_index,
df_zcta,
by=c('ZCTA'))
head(df_index)
# create indices for subjects since we are doing this by smi
start_index = 1
end_index = NULL
# by smi, get all the zips and find the distance between them
smi_list = unique(df_panel[,'Scantrack_Market_Identifier_Cd'])
smi = smi_list[1]
# get all observaionts from smi
temp_panel = df_panel[df_panel['Scantrack_Market_Identifier_Cd']==smi,]
# get number of observations from smi
N_smi = dim(temp_panel)[1]
# create index for using in the weight matrix
if(is.null(end_index)){
end_index = N_smi
}else{
start_index = end_index + 1
end_index = start_index + N_smi - 1
}
indices = start_index:end_index
# list of zip codes
zip_list = as.vector(temp_panel[,'Panelist_ZipCd'])
# zip to zctas
df_index = data.frame(large_matrix_index=indices,zip=zip_list,sort_index=1:N_smi)
df_index = merge(df_index,
zip_to_zcta,
by.x=c('zip'),
by.y=c('ZIP'))
# pad 0s for zips
padded_zip = c()
for(zip in zip_list){
if(nchar(zip)<5){
padded_zip = c(padded_zip,paste(c(rep("0",5-nchar(zip)),zip),collapse=''))
}else{
padded_zip = c(padded_zip,zip)
}
}
# get polygons for list of zips
df <- zctas(cb = TRUE, starts_with = padded_zip,refresh=TRUE,year=2010)
# create zcta index
zcta_index = 1:dim(df)[1]
df_zcta = data.frame(ZCTA=df@data[,'ZCTA5'],submatrix_index=zcta_index)
df_index = merge(df_index,
df_zcta,
by=c('ZCTA'))
# find center of polygons
polygon_centroids = gCentroid(df,byid=TRUE)
# get distance between points
# distance is in meters
dist_points = pointDistance(coordinates(polygon_centroids),coordinates(polygon_centroids),lonlat=TRUE,allpairs=T)
dist_points = Matrix(as.matrix(dist_points/1000),sparse=TRUE) #meters -> kilometers
# re-order matrix for submatrix
dist_points = dist_points[df_index[,'submatrix_index']-N_smi,]
dist_points = dist_points[,df_index[,'submatrix_index']]
# replace distance points in the weight matrix
weight_matrix[df_index[,'large_matrix_index'],df_index[,'large_matrix_index']] = dist_points
df_index[,'large_matrix_index']
length(df_index[,'large_matrix_index'])
dim(dist_points)
# get distance between points
# distance is in meters
dist_points = pointDistance(coordinates(polygon_centroids),coordinates(polygon_centroids),lonlat=TRUE,allpairs=T)
dist_points = Matrix(as.matrix(dist_points/1000),sparse=TRUE) #meters -> kilometers
# re-order matrix for submatrix
dist_points = dist_points[df_index[,'submatrix_index'],]
dist_points = dist_points[,df_index[,'submatrix_index']]
# replace distance points in the weight matrix
weight_matrix[df_index[,'large_matrix_index'],df_index[,'large_matrix_index']] = dist_points
smi = smi_list[2]
# get all observaionts from smi
temp_panel = df_panel[df_panel['Scantrack_Market_Identifier_Cd']==smi,]
# get number of observations from smi
N_smi = dim(temp_panel)[1]
# create index for using in the weight matrix
if(is.null(end_index)){
end_index = N_smi
}else{
start_index = end_index + 1
end_index = start_index + N_smi - 1
}
indices = start_index:end_index
# list of zip codes
zip_list = as.vector(temp_panel[,'Panelist_ZipCd'])
# zip to zctas
df_index = data.frame(large_matrix_index=indices,zip=zip_list,sort_index=1:N_smi)
df_index = merge(df_index,
zip_to_zcta,
by.x=c('zip'),
by.y=c('ZIP'))
# pad 0s for zips
padded_zip = c()
for(zip in zip_list){
if(nchar(zip)<5){
padded_zip = c(padded_zip,paste(c(rep("0",5-nchar(zip)),zip),collapse=''))
}else{
padded_zip = c(padded_zip,zip)
}
}
# get polygons for list of zips
df <- zctas(cb = TRUE, starts_with = padded_zip,refresh=TRUE,year=2010)
# create zcta index
zcta_index = 1:dim(df)[1]
df_zcta = data.frame(ZCTA=df@data[,'ZCTA5'],submatrix_index=zcta_index)
df_index = merge(df_index,
df_zcta,
by=c('ZCTA'))
# find center of polygons
polygon_centroids = gCentroid(df,byid=TRUE)
# get distance between points
# distance is in meters
dist_points = pointDistance(coordinates(polygon_centroids),coordinates(polygon_centroids),lonlat=TRUE,allpairs=T)
dist_points = Matrix(as.matrix(dist_points/1000),sparse=TRUE) #meters -> kilometers
# re-order matrix for submatrix
dist_points = dist_points[df_index[,'submatrix_index'],]
dist_points = dist_points[,df_index[,'submatrix_index']]
# replace distance points in the weight matrix
weight_matrix[df_index[,'large_matrix_index'],df_index[,'large_matrix_index']] = dist_points
# create directories
matrix_dir = "C:/Users/ryanl/Dropbox/club_stores/data/hms/analysis/weight_matrices/"
# write matrix
file_name = paste(matrix_dir,'zcta_weight_',year,'.txt',sep='')
year=2005
# write matrix
file_name = paste(matrix_dir,'zcta_weight_',year,'.txt',sep='')
writeMM(weight_matrix,file_name)
# geospatial
library(tigris)
library(rgeos)
library(sp)
library(raster)
# sparse matrix
library(Matrix)
# to prevent downloading of ztcas every time
options(tigris_use_cache=TRUE)
# create directories
matrix_dir = "C:/Users/ryanl/Dropbox/club_stores/data/hms/analysis/weight_matrices/"
raw_dir = "C:/Users/ryanl/Dropbox/club_stores/data/hms/raw/"
#### ~ Preprocess Data ~ ####
## ~ Load Zip to ZCTA Crosswalk ~ ##
zip_to_zcta = read.csv('C:/Users/ryanl/Dropbox/club_stores/data/raw/zcta/zip_to_zcta_2010.csv',
colClasses=c(rep("character",5)))
## ~ Load HMS Data ~ ##
# get all years
year_available = 2004:2016
# loop through all the years of data
for(year in year_available){
in_file = paste(raw_dir,year,'/Annual_Files/rls_panelists_',year,'.csv',sep='')
# load panel dataset
df_panel = read.csv(in_file)
# get number of columns
ncols = dim(df_panel)[2]
# re-read in file
df_panel = read.csv(in_file,
colClasses=c(rep("character",ncols)))
# keep only household codes, zips, and SMIs
df_panel = df_panel[,c('Household_Cd','Panelist_ZipCd','Scantrack_Market_Identifier_Cd')]
# create sparse matrix that is N x N,
#   where N = number of individuals in the data
N = dim(df_panel)[1]
weight_matrix = Matrix(data=0,nrow=N,ncol=N,sparse=TRUE)
# create indices for subjects since we are doing this by smi
start_index = 1
end_index = NULL
}
in_file = paste(raw_dir,'rls_panelists_',year,'.csv',sep='')
in_file
# load panel dataset
df_panel = read.csv(in_file)
# get number of columns
ncols = dim(df_panel)[2]
# re-read in file
df_panel = read.csv(in_file,
colClasses=c(rep("character",ncols)))
cat('Current year: ',year,collapse='')
cat('Current year:',year,collapse='')
source('~/temp_File.R', echo=TRUE)
library(maptools)
# read shapefiles
shape=readShapePoly('C:\Users\ryanl\Downloads\tl_2010_01_zcta510\tl_2010_01_zcta510.shp')
# read shapefiles
shape=readShapePoly('C:/Users/ryanl/Downloads/tl_2010_01_zcta510/tl_2010_01_zcta510.shp')
# read shapefiles
shape=readOGR('C:/Users/ryanl/Downloads/tl_2010_01_zcta510/tl_2010_01_zcta510.shp')
library(rgdal)
# read shapefiles
shape=readOGR('C:/Users/ryanl/Downloads/tl_2010_01_zcta510/tl_2010_01_zcta510.shp')
colnames(shape@data)
# read shapefiles
shape=readOGR('C:/Users/ryanl/Downloads/tl_2010_us_zcta510/tl_2010_us_zcta510.shp')
colnames(shape@data)
t=unique(shape@data['ZCTA5CE10'])
length(t)
t
dim(t)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
help(merge)
df_l_club = read.csv('C:\Users\ryanl\Dropbox\r_assignments\assign_0\lend_club.csv')
df_l_club = read.csv('C:/Users/ryanl/Dropbox/r_assignments/assign_0/lend_club.csv')
dim(df_l_club)
colnames(df_l_club)
index=sampe(1:nrows(df_l_club),.1*df_l_club)
df_l_club = df_l_club[index,]
help(sample)
index=sample(1:nrows(df_l_club),.1*df_l_club)
index=sample(1:dim(df_l_club)[1],.1*df_l_club)
index=sample(1:dim(df_l_club)[1],.1*dim(df_l_club)[1])
df_l_club = df_l_club[index,]
write.csv('C:/Users/ryanl/Dropbox/r_assignments/assign_0/lend_club_10pc.csv')
write.csv(df_l_club,'C:/Users/ryanl/Dropbox/r_assignments/assign_0/lend_club_10pc.csv')
help(lagsarlm)
library(spdep)
install.packages("spdep")
library(spdep)
help(lagsarlm)
x=c()
y=c()
rm(list(x,y))
rm(c(x,y))
help(rm)
rm(list=c(x,y))
x
x=c("1")
y=c("2")
rm(list=c(x,y))
rm(list=c(x,y))
x
rm(list=c('x','y'))
x
x='1'
print(x)
cat(paste('x=',x,sep=''))
print(paste('x=',x,sep=''))
x=('test','temp','list')
x=c('test','temp','list')
grep('es',x)
grep('em',x)
x='thistest"has"some"quotes"'
regmatches(x, gregexpr('"[^"]*"', x))[[1]]
regmatches(x, gregexpr('"[^"]*"', x))[[1]]
[1]
regmatches(x, gregexpr('"[^"]*"', x))[[1]][1]
x='test/this/'
grep('/',x)
grep('\',x)
)
)
q
x='test/test'
grep("\",x)
)
(_)
saf
zx
grep
grep()
))
q
""
\\
"\\"
grep("\\",x)
grep("\\",x)
grep("/\",x)
grep("\\")
grep(""\""",x)
x
grep("\\",x)
grep('\\',x)
grep('\\\',x)
'\\'
grep('\\\\',x)
grep('/\',x)
'\\'
x='test\test'
x
grep('\\\\',x)
grep('\\',x)
cat(x)
x='test\\test'
grep('\\\\',x)
is.null(grep('\\\\',x))
is.na(grep('\\\\',x))
is.na(grep('/',x))
is.null(grep('/',x))
is.null(is.na(grep('/',x)))
grep('/',x)
grep('/',x)==0
c(1,2)[T,F]
x=c(1,2)
x[c(T,F)]
c(1,2)[c(T,F)]
paste(c('1','2'),sep='')
cat(paste(c('1','2'),sep=''))
x=cat(paste(c('1','2'),sep=''))
x
paste(c('1','2'),sep='')[2]
x=c(1,2)
y=c(x,3)
y
x=c(1,2)
y=c(2,1)
x==y
sort(x)
sort(y)
sort(x)!=sort(y)
any(sort(x)!=sort(y))
help(cwd)
help(chdir)
help(chwd)
help(cd)
## Data directory
data_dir = "C:/Users/ryanl/Dropbox/r_assignments/assign_0/data/"
setwd(data_dir)
## Load datasets
## Load Air Revenue Data ##
us_air_rev = read.csv('us_air_rev.csv')
## Load Air Load Factor Data ##
us_load_factor = read.csv('us_load_factor.csv')
colnames(us_load_factor)
help(as.ts)
help(lm)
